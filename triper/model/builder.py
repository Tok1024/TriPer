import torch
from typing import Optional, Dict, Any, Tuple
from llava.model.builder import load_pretrained_model
from .triper_arch import TriperModel
from triper.configs.triper_config import TriperConfig
from .audio import build_audio_encoder
from .audio import build_audio_projector


def from_pretrained_components(
    llava_model_path: str,
    audio_encoder_path: Optional[str] = None,
    audio_projector_path: Optional[str] = None,
    audio_config: Optional[Dict] = None,
    freeze_llava: bool = True,
    device_map: str = "auto"
) -> Tuple[Any, TriperModel, Any, int, Any]:
    """
    ä»é¢„è®­ç»ƒç»„ä»¶æ„å»ºTriperæ¨¡å‹
    
    Returns:
        tokenizer, triper_model, image_processor, context_len, audio_encoder
    """
    
    print("ğŸ”„ Building Triper model from components...")
    print(f"   LLaVA model: {llava_model_path}")
    print(f"   Audio encoder: {audio_encoder_path}")
    print(f"   Audio projector: {'Built from config' if audio_projector_path is None else audio_projector_path}")
    print(f"   Freeze LLaVA: {freeze_llava}")
    
    # 1. åŠ è½½LLaVAæ¨¡å‹
    print("ğŸ”„ Loading LLaVA model...")
    tokenizer, llava_model, image_processor, context_len = load_pretrained_model(
        model_path=llava_model_path,
        model_base=None,
        model_name=llava_model_path.split('/')[-1],
        device_map=device_map
    )
    
    # # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿å›¾åƒtokenæ­£ç¡®é…ç½®
    # print("ğŸ”„ Configuring image tokens...")
    # from llava.constants import DEFAULT_IMAGE_TOKEN, IMAGE_TOKEN_INDEX
    
    # # æ£€æŸ¥å¹¶æ·»åŠ å›¾åƒtoken
    # if DEFAULT_IMAGE_TOKEN not in tokenizer.get_vocab():
    #     print(f"æ·»åŠ å›¾åƒtoken: {DEFAULT_IMAGE_TOKEN}")
    #     tokenizer.add_tokens([DEFAULT_IMAGE_TOKEN])
        
    #     # è°ƒæ•´æ¨¡å‹çš„embeddingå±‚
    #     llava_model.resize_token_embeddings(len(tokenizer))
        
    #     # æ›´æ–°IMAGE_TOKEN_INDEX
    #     new_image_id = tokenizer.convert_tokens_to_ids(DEFAULT_IMAGE_TOKEN)
    #     import llava.constants
    #     import triper.constants
    #     llava.constants.IMAGE_TOKEN_INDEX = new_image_id
    #     triper.constants.IMAGE_TOKEN_INDEX = new_image_id
    #     print(f"æ›´æ–°IMAGE_TOKEN_INDEXä¸º: {new_image_id}")
    # else:
    #     print(f"âœ… å›¾åƒtokenå·²å­˜åœ¨: {DEFAULT_IMAGE_TOKEN}")
    
    # 2. æ„å»ºéŸ³é¢‘ç¼–ç å™¨ï¼ˆå¤–éƒ¨ç»„ä»¶ï¼‰
    audio_encoder = None
    if audio_encoder_path and audio_config:
        try:
            print("ğŸ”„ Building audio encoder...")
            
            # ç¡®ä¿éŸ³é¢‘é…ç½®åŒ…å«è·¯å¾„
            if 'audio_model_path' not in audio_config:
                audio_config['audio_model_path'] = audio_encoder_path
            
            # åˆ›å»ºä¸´æ—¶é…ç½®å¯¹è±¡æ¥æ„å»ºç¼–ç å™¨
            from triper.configs.triper_config import TriperConfig
            temp_config = TriperConfig(**audio_config)
            
            audio_encoder = build_audio_encoder(temp_config)
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šå°†éŸ³é¢‘ç¼–ç å™¨ç§»åˆ°GPU
            if audio_encoder is not None:
                # è·å–ä¸»æ¨¡å‹çš„è®¾å¤‡
                main_device = next(llava_model.parameters()).device
                print(f"ğŸ”„ Moving audio encoder to device: {main_device}")
                
                audio_encoder = audio_encoder.to(main_device)
                
                # å†»ç»“éŸ³é¢‘ç¼–ç å™¨å‚æ•°
                for param in audio_encoder.parameters():
                    param.requires_grad = False
                print("ğŸ”’ Audio encoder parameters frozen")
                
                print(f"âœ… Audio encoder built and moved to {main_device}: {type(audio_encoder).__name__}")
            
        except Exception as e:
            print(f"âš ï¸ Failed to build audio encoder: {e}")
            import traceback
            traceback.print_exc()
    
    # 3. åˆ›å»ºTriperé…ç½®å¹¶å°†æŠ•å½±å™¨ä¹Ÿç§»åˆ°GPU
    print("ğŸ”„ Creating Triper model...")
    
    config_dict = {
        'model_type': 'triper',
        'freeze_llava': freeze_llava,
        'hidden_size': getattr(llava_model.config, 'hidden_size', 5120),
        'vocab_size': getattr(llava_model.config, 'vocab_size', 32000),
    }
    
    # åˆå¹¶éŸ³é¢‘é…ç½®
    if audio_config:
        config_dict.update(audio_config)
    
    triper_config = TriperConfig(**config_dict)
    
    # 4. åˆ›å»ºTriperæ¨¡å‹
    triper_model = TriperModel(triper_config)
    
    # ğŸ”§ å°†Triperæ¨¡å‹ç§»åˆ°ä¸LLaVAç›¸åŒçš„è®¾å¤‡
    main_device = next(llava_model.parameters()).device
    print(f"ğŸ”„ Moving Triper model to device: {main_device}")
    triper_model = triper_model.to(main_device)
    
    # 5. é™„åŠ ç»„ä»¶
    triper_model.attach_llava_model(llava_model)
    
    if audio_encoder is not None:
        triper_model.set_audio_encoder(audio_encoder)
        
    triper_model.set_components(tokenizer, image_processor, context_len)
    
    print("âœ… Triper model created successfully!")
    triper_model.print_model_summary()
    
    return tokenizer, triper_model, image_processor, context_len, audio_encoder


def _create_triper_config_from_llava(
    llava_config, 
    audio_config: Optional[Dict[str, Any]] = None,
    freeze_llava: bool = True,
    freeze_audio_encoder: bool = True
) -> TriperConfig:
    """ä»LLaVAé…ç½®åˆ›å»ºTriperé…ç½®"""
    
    # è·å–LLaVAé…ç½®å­—å…¸
    if hasattr(llava_config, 'to_dict'):
        config_dict = llava_config.to_dict()
    else:
        # å¦‚æœæ²¡æœ‰to_dictæ–¹æ³•ï¼Œæ‰‹åŠ¨æå–å…³é”®é…ç½®
        config_dict = {
            'hidden_size': getattr(llava_config, 'hidden_size', 4096),
            'vocab_size': getattr(llava_config, 'vocab_size', 32000),
            'num_attention_heads': getattr(llava_config, 'num_attention_heads', 32),
            'num_hidden_layers': getattr(llava_config, 'num_hidden_layers', 32),
            'intermediate_size': getattr(llava_config, 'intermediate_size', 11008),
        }
    
    # ä¿®æ”¹æ¨¡å‹ç±»å‹
    config_dict['model_type'] = 'triper'
    config_dict['architectures'] = ['TriperModel']
    
    # æ·»åŠ Triperç‰¹å®šé…ç½®
    config_dict.update({
        'freeze_llava': freeze_llava,
        'freeze_audio_encoder': freeze_audio_encoder,
    })
    
    # æ·»åŠ éŸ³é¢‘ç›¸å…³é…ç½®
    default_audio_config = {
        'mm_audio_encoder': 'whisper_vq',
        'audio_hidden_size': 768,
        'use_audio_proj': True,
    }
    
    if audio_config:
        default_audio_config.update(audio_config)
    
    config_dict.update(default_audio_config)
    
    return TriperConfig(**config_dict)



import torch
import gc
import os
import sys
import pdb

# è®¾ç½®è·¯å¾„
sys.path = [p for p in sys.path if 'triper-project' not in p]
sys.path.append('/home/wly/szl_all_code/triper-project')

# æ¸…ç†ç¼“å­˜
torch.cuda.empty_cache()
gc.collect()

def debug_triper_generate():
    """è°ƒè¯•Triperç”Ÿæˆè¿‡ç¨‹"""
    
    print("ğŸ”§ å¼€å§‹è°ƒè¯•Triperç”Ÿæˆè¿‡ç¨‹...")
    
    # åŠ è½½æ¨¡å‹
    from triper.model import from_pretrained_components
    from triper.data import TriperDataset, TriperDataCollator

    audio_config = {
        'mm_audio_encoder': 'whisper_vq',
        'audio_hidden_size': 1280,
        'audio_model_path': '/sda1/glm-4-voice-tokenizer',
        'audio_projector_type': 'mlp2x_gelu',
        'audio_projector_hidden_dim': 2048,
        'dropout': 0.1
    }

    print("ğŸ“¦ åŠ è½½æ¨¡å‹ç»„ä»¶...")
    tokenizer, triper_model, image_processor, context_len, audio_encoder = from_pretrained_components(
        llava_model_path="/sda1/llava-v1.5-13b",
        audio_encoder_path="/sda1/glm-4-voice-tokenizer",
        audio_projector_path=None,
        audio_config=audio_config,
        freeze_llava=True,
        device_map="cuda:3"
    )

    print("ğŸ“Š åŠ è½½æ•°æ®...")
    dataset = TriperDataset(
        json_path='/home/wly/szl_all_code/triper-project/data/simple_data_20_samples.json',
        media_root_path='/home/wly/szl_all_code/triper-project/data',
    )

    collator = TriperDataCollator(
        tokenizer=tokenizer,
        image_processor=image_processor,
        audio_processor=audio_encoder,
        model_cfg=triper_model.llava_model.config
    )

    # å‡†å¤‡å•ä¸ªæ ·æœ¬è¿›è¡Œè°ƒè¯•
    print("ğŸ§ª å‡†å¤‡å•ä¸ªæ ·æœ¬...")
    single_sample = [dataset[0]]
    single_batch = collator(single_sample)

    # ç§»åŠ¨åˆ°è®¾å¤‡
    device_batch = {}
    for k, v in single_batch.items():
        if hasattr(v, 'to'):
            device_batch[k] = v.to(triper_model.device)
        else:
            device_batch[k] = v

    print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ:")
    print(f"  input_ids: {device_batch['input_ids'].shape}")
    print(f"  attention_mask: {device_batch['attention_mask'].shape}")
    print(f"  images: {device_batch['images'].shape}")
    print(f"  audio_features: {device_batch['audio_features'].shape}")


    # ğŸ”§ è®¾ç½®æ–­ç‚¹ - åœ¨è°ƒç”¨generateä¹‹å‰
    print("ğŸš¨ è®¾ç½®æ–­ç‚¹1: è°ƒç”¨triper_model.generateä¹‹å‰")
    pdb.set_trace()
    
    # åœ¨pdbä¸­ä½ å¯ä»¥æ£€æŸ¥:
    # - device_batch çš„å†…å®¹
    # - triper_model çš„çŠ¶æ€
    # - å„ç§å‚æ•°çš„å€¼
    
    try:
        print("ğŸ¯ å¼€å§‹è°ƒç”¨triper_model.generate...")
        
        # ğŸ”§ åœ¨generateæ–¹æ³•å†…éƒ¨ä¹Ÿè®¾ç½®æ–­ç‚¹
        # æˆ‘ä»¬éœ€è¦ä¿®æ”¹generateæ–¹æ³•æ¥æ·»åŠ æ›´å¤šæ–­ç‚¹
        original_generate = triper_model.generate
        
        def debug_generate(*args, **kwargs):
            print("ğŸš¨ è®¾ç½®æ–­ç‚¹2: è¿›å…¥generateæ–¹æ³•å†…éƒ¨")
            pdb.set_trace()
            # åœ¨è¿™é‡Œä½ å¯ä»¥æ£€æŸ¥ä¼ å…¥çš„å‚æ•°
            
            return original_generate(*args, **kwargs)
        
        # ä¸´æ—¶æ›¿æ¢generateæ–¹æ³•
        triper_model.generate = debug_generate
        
        response = triper_model.generate(
            input_ids=device_batch['input_ids'],
            attention_mask=device_batch['attention_mask'],
            images=device_batch['images'],
            audio_features=device_batch['audio_features'],
            max_new_tokens=5,  # ç”¨å¾ˆå°‘çš„tokenä¾¿äºè°ƒè¯•
            temperature=0.1,
            do_sample=False,  # è´ªå¿ƒæœç´¢ï¼Œç¡®å®šæ€§ç»“æœ
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id
        )
        
        print(f"âœ… ç”ŸæˆæˆåŠŸ: {response.shape}")
        
        # è§£ç ç»“æœ
        original_len = device_batch['input_ids'].shape[1]
        if response.shape[1] > original_len:
            generated_part = response[0, original_len:]
            generated_text = tokenizer.decode(generated_part, skip_special_tokens=True)
            print(f"æ–°ç”Ÿæˆçš„æ–‡æœ¬: '{generated_text}'")
        else:
            generated_text = tokenizer.decode(response[0], skip_special_tokens=True)
            print(f"ç”Ÿæˆçš„æ–‡æœ¬: '{generated_text}'")

    except Exception as e:
        print(f"âŒ é”™è¯¯å‘ç”Ÿ: {e}")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        
        # ğŸ”§ è®¾ç½®æ–­ç‚¹3: é”™è¯¯å‘ç”Ÿæ—¶
        print("ğŸš¨ è®¾ç½®æ–­ç‚¹3: é”™è¯¯å‘ç”Ÿæ—¶")
        pdb.set_trace()
        
        # åœ¨è¿™é‡Œä½ å¯ä»¥æ£€æŸ¥:
        # - é”™è¯¯çš„è¯¦ç»†ä¿¡æ¯
        # - å½“å‰çš„å˜é‡çŠ¶æ€
        # - è°ƒç”¨æ ˆ
        
        import traceback
        traceback.print_exc()
        raise

def debug_llava_methods():
    """ä¸“é—¨è°ƒè¯•LLaVAçš„ç›¸å…³æ–¹æ³•"""
    
    print("ğŸ” è°ƒè¯•LLaVAæ–¹æ³•è°ƒç”¨...")
    
    # é¦–å…ˆåŠ è½½å¿…è¦ç»„ä»¶ï¼ˆç®€åŒ–ç‰ˆï¼‰
    from triper.model import from_pretrained_components
    
    print("ğŸ“¦ å¿«é€ŸåŠ è½½æ¨¡å‹...")
    tokenizer, triper_model, image_processor, context_len, audio_encoder = from_pretrained_components(
        llava_model_path="/sda1/llava-v1.5-13b",
        audio_encoder_path="/sda1/glm-4-voice-tokenizer",
        audio_projector_path=None,
        audio_config={'mm_audio_encoder': 'whisper_vq', 'audio_hidden_size': 1280},
        freeze_llava=True,
        device_map="cuda:3"
    )
    
    # æ£€æŸ¥LLaVAæ¨¡å‹çš„æ–¹æ³•
    print("ğŸ” æ£€æŸ¥LLaVAæ¨¡å‹æ–¹æ³•:")
    llava_model = triper_model.llava_model
    print(f"  ç±»å‹: {type(llava_model).__name__}")
    print(f"  æœ‰generateæ–¹æ³•: {hasattr(llava_model, 'generate')}")
    print(f"  æœ‰prepare_inputs_labels_for_multimodal: {hasattr(llava_model, 'prepare_inputs_labels_for_multimodal')}")
    print(f"  æœ‰prepare_inputs_for_generation: {hasattr(llava_model, 'prepare_inputs_for_generation')}")
    
    # ğŸ”§ è®¾ç½®æ–­ç‚¹4: æ£€æŸ¥LLaVAæ¨¡å‹çŠ¶æ€
    print("ğŸš¨ è®¾ç½®æ–­ç‚¹4: æ£€æŸ¥LLaVAæ¨¡å‹çŠ¶æ€")
    pdb.set_trace()
    
    # åœ¨è¿™é‡Œä½ å¯ä»¥:
    # - æŸ¥çœ‹llava_modelçš„æ‰€æœ‰å±æ€§å’Œæ–¹æ³•
    # - æ£€æŸ¥llava_model.config
    # - æŸ¥çœ‹æ¨¡å‹çš„å†…éƒ¨ç»“æ„

if __name__ == "__main__":
    print("ğŸ¯ Triperç”Ÿæˆè°ƒè¯•è„šæœ¬")
    print("=" * 50)
    
    try:
        # é€‰æ‹©è°ƒè¯•æ¨¡å¼
        print("é€‰æ‹©è°ƒè¯•æ¨¡å¼:")
        print("1. è°ƒè¯•å®Œæ•´ç”Ÿæˆè¿‡ç¨‹ (debug_triper_generate)")
        print("2. è°ƒè¯•LLaVAæ–¹æ³• (debug_llava_methods)")
        
        choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2): ").strip()
        
        if choice == "1":
            debug_triper_generate()
        elif choice == "2":
            debug_llava_methods()
        else:
            print("é»˜è®¤è¿è¡Œå®Œæ•´è°ƒè¯•...")
            debug_triper_generate()
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ è°ƒè¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ è°ƒè¯•è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print("\nğŸ è°ƒè¯•å®Œæˆ")